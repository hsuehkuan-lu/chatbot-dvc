{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import data_loader.preprocess as module_preprocess\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer\n",
    "\n",
    "\n",
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "config = ConfigParser(json.load(open('config.json', 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "# preprocess\n",
    "# config.init_obj('preprocess', module_preprocess)\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data, save_dir=config.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<init>', '<eos>', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.TEXT.vocab.itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'talk': ['can', 'we', 'make', 'this', 'quick', '?', ' ', 'roxanne', 'korrine', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad', '.', ' ', 'again', '.'], 'response': ['well', ',', 'i', 'thought', 'we', \"'d\", 'start', 'with', 'pronunciation', ',', 'if', 'that', \"'s\", 'okay', 'with', 'you', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(data_loader.dataset.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequential': True, 'use_vocab': True, 'init_token': '<init>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'fix_length': 32, 'dtype': torch.int64, 'preprocessing': None, 'postprocessing': None, 'lower': True, 'tokenizer_args': (<bound method ChatbotDataLoader._tokenizer of <data_loader.data_loaders.ChatbotDataLoader object at 0x13058f370>>, 'en'), 'tokenize': <bound method ChatbotDataLoader._tokenizer of <data_loader.data_loaders.ChatbotDataLoader object at 0x13058f370>>, 'include_lengths': True, 'batch_first': False, 'pad_token': '<pad>', 'pad_first': False, 'truncate_first': False, 'stop_words': None, 'is_target': False, 'vocab': <torchtext.vocab.Vocab object at 0x1325475e0>}\n"
     ]
    }
   ],
   "source": [
    "print(vars(data_loader.TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_config': {'name': 'Chatbot', 'n_gpu': 1, 'embed_size': 50, 'hidden_size': 256, 'encoder_arch': {'type': 'ChatbotEncoder', 'args': {'n_layers': 1, 'dropout': 0.1}}, 'attn_arch': {'type': 'Attention', 'args': {'method': 'concat'}}, 'decoder_arch': {'type': 'LuongAttnDecoderRNN', 'args': {'attn_model': 'concat', 'n_layers': 1, 'dropout': 0.1}}, 'preprocess': {'type': 'ChatbotDataPreprocess', 'args': {'data_dir': 'data/cornell movie-dialogs corpus'}}, 'data_loader': {'type': 'ChatbotDataLoader', 'args': {'data_dir': 'data/cornell movie-dialogs corpus', 'filename': 'formatted_movie_lines.csv', 'text_field_path': None, 'vocab_path': None, 'batch_size': 128, 'sent_len': 32, 'init_token': '<init>', 'eos_token': '<eos>', 'min_freq': 5, 'shuffle': True, 'validation_split': 0.1, 'debug': True}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 0.0001, 'weight_decay': 0, 'amsgrad': True}}, 'loss': 'mask_nll_loss', 'metrics': ['accuracy', 'top_k_acc'], 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}}, 'trainer': {'epochs': 10, 'save_dir': 'saved/', 'save_period': 1, 'verbosity': 2, 'monitor': 'min val_loss', 'early_stop': 2, 'clip': 50.0, 'tensorboard': True}}, 'resume': None, '_save_dir': PosixPath('saved/models/Chatbot/1022_211956'), '_log_dir': PosixPath('saved/log/Chatbot/1022_211956'), 'log_levels': {0: 30, 1: 20, 2: 10}}\n"
     ]
    }
   ],
   "source": [
    "print(config.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.field.Field object at 0x12b6f9220>\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.TEXT.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.TEXT.vocab.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data_loader.TEXT.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(10, [10,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 2, 1, 6, 0, 6, 6, 5, 3, 9, 4, 6, 1, 8, 0, 5, 4, 1, 6, 7, 3, 1, 2, 2,\n",
       "         8, 8, 3, 3, 4, 6, 1, 2],\n",
       "        [3, 6, 0, 5, 0, 5, 2, 9, 4, 0, 4, 8, 1, 2, 6, 9, 7, 5, 5, 6, 4, 4, 2, 9,\n",
       "         3, 8, 2, 6, 6, 1, 2, 7],\n",
       "        [3, 8, 7, 3, 3, 8, 5, 1, 9, 8, 0, 0, 7, 8, 6, 5, 1, 9, 0, 3, 5, 4, 6, 1,\n",
       "         3, 6, 3, 3, 7, 1, 7, 1],\n",
       "        [9, 6, 7, 9, 9, 5, 6, 6, 2, 9, 7, 4, 6, 5, 9, 8, 0, 6, 1, 4, 9, 7, 4, 0,\n",
       "         5, 0, 1, 9, 5, 1, 8, 5],\n",
       "        [4, 5, 6, 4, 7, 7, 4, 5, 3, 3, 0, 5, 9, 5, 3, 8, 0, 3, 7, 8, 6, 3, 4, 8,\n",
       "         8, 5, 6, 7, 1, 0, 2, 0],\n",
       "        [1, 2, 2, 1, 6, 0, 9, 6, 6, 1, 6, 8, 2, 4, 1, 4, 3, 5, 2, 2, 8, 9, 4, 2,\n",
       "         8, 3, 4, 6, 6, 5, 6, 9],\n",
       "        [9, 5, 5, 8, 9, 9, 1, 1, 2, 8, 1, 1, 3, 3, 9, 2, 0, 3, 9, 5, 8, 5, 4, 2,\n",
       "         2, 3, 1, 9, 6, 9, 6, 6],\n",
       "        [3, 7, 1, 4, 3, 7, 2, 2, 0, 9, 4, 3, 5, 8, 0, 7, 5, 7, 7, 9, 4, 7, 5, 1,\n",
       "         0, 3, 1, 2, 6, 2, 7, 9],\n",
       "        [2, 2, 1, 6, 2, 4, 5, 0, 3, 3, 7, 4, 3, 1, 1, 0, 0, 2, 4, 9, 6, 1, 9, 7,\n",
       "         9, 4, 1, 7, 7, 9, 3, 5],\n",
       "        [4, 2, 5, 4, 0, 5, 4, 7, 1, 3, 7, 7, 5, 2, 9, 3, 5, 2, 8, 8, 3, 1, 0, 3,\n",
       "         4, 8, 7, 0, 7, 1, 4, 2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(data_loader.valid_iter.dataset))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from torchtext.data import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 89, 'dataset': <torchtext.data.dataset.Dataset object at 0x132547430>, 'fields': dict_keys(['talk', 'response']), 'input_fields': ['talk', 'response'], 'target_fields': [], 'talk': (tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 0,  0,  5,  ...,  5, 77,  0],\n",
      "        [ 7,  7, 34,  ..., 16,  8, 15],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  0,  1, 31],\n",
      "        [ 1,  1,  1,  ...,  4,  1, 79],\n",
      "        [ 1,  1,  1,  ...,  3,  1,  3]]), tensor([19, 20,  5, 12, 26, 14,  4, 11,  3, 32,  6, 16, 16, 32,  5,  6,  5, 18,\n",
      "        16, 31, 14,  6, 22,  9,  9,  5,  4, 15, 27, 15, 14,  6, 32, 10, 11, 15,\n",
      "        14, 23,  4,  9, 14,  4,  6, 13, 13,  5, 13,  3,  9, 15, 19,  7,  5, 32,\n",
      "        11, 25,  3, 17, 31,  4, 13, 32,  6,  8, 13,  3, 29, 11, 29, 10,  6, 13,\n",
      "        11, 23, 14, 12,  5,  6,  6, 21,  7,  8,  4, 32,  4, 26, 32,  4, 32])), 'response': (tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [25, 17,  6,  ...,  6,  0, 77],\n",
      "        [11,  6, 65,  ..., 23,  0, 36],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  1,  4,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  3,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1]]), tensor([14,  6, 15,  5, 31,  5,  8,  6, 15, 12, 26, 15,  4, 12, 18, 11, 12, 18,\n",
      "        32,  7, 19,  8,  6, 28,  4,  4, 11, 32, 21, 32, 20, 13,  8, 15,  3,  5,\n",
      "        12, 20,  9, 15, 32, 32,  3,  4, 10, 23,  4, 32,  5, 25,  4,  6, 22,  5,\n",
      "        27,  4,  8, 17, 23,  4, 23, 15, 32,  7, 14, 12,  3,  5, 19,  6,  9,  6,\n",
      "        13, 11, 16, 11,  6, 24,  6, 12,  8,  4, 10,  7, 19, 31,  6, 31,  9]))}\n",
      "{'sequential': True, 'use_vocab': True, 'init_token': '<init>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'fix_length': 32, 'dtype': torch.int64, 'preprocessing': None, 'postprocessing': None, 'lower': True, 'tokenizer_args': (<bound method ChatbotDataLoader._tokenizer of <data_loader.data_loaders.ChatbotDataLoader object at 0x13058f370>>, 'en'), 'tokenize': <bound method ChatbotDataLoader._tokenizer of <data_loader.data_loaders.ChatbotDataLoader object at 0x13058f370>>, 'include_lengths': True, 'batch_first': False, 'pad_token': '<pad>', 'pad_first': False, 'truncate_first': False, 'stop_words': None, 'is_target': False, 'vocab': <torchtext.vocab.Vocab object at 0x1325475e0>}\n",
      "---\n",
      "{'batch_size': 89, 'dataset': <torchtext.data.dataset.Dataset object at 0x132547430>, 'fields': dict_keys(['talk', 'response']), 'input_fields': ['talk', 'response'], 'target_fields': [], 'talk': (tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [ 5, 35, 44,  ..., 52,  0,  0],\n",
      "        [22, 60,  0,  ..., 15,  7, 16],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1]]), tensor([29,  6,  9, 11,  6, 20, 18, 14,  3,  5,  3, 19,  9,  9, 25, 14, 14,  5,\n",
      "         4, 32, 13, 32, 13,  8,  3,  4, 14,  5, 16, 31, 32, 16, 15,  4, 29, 14,\n",
      "         5,  5,  5, 11,  6, 12, 31,  6, 26,  6, 11,  3,  4, 15, 23, 13, 32, 17,\n",
      "        13, 15, 10, 22, 23, 21,  4,  4, 32, 12, 13, 27,  8,  4,  5,  6,  6, 15,\n",
      "        16,  4, 11, 26, 32, 32, 19, 14, 10,  6,  7, 32, 13,  9, 11,  7,  6])), 'response': (tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
      "        [51, 11, 77,  ..., 30,  0,  0],\n",
      "        [ 3, 32,  8,  ...,  3,  7, 16],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1]]), tensor([ 3,  8,  4, 27, 24,  6, 18,  5, 32,  4, 15, 14,  5, 15,  4, 12, 16, 15,\n",
      "        31,  9,  6,  7, 10,  7,  8,  9, 20,  6,  4,  7, 12, 32, 32, 32, 19, 32,\n",
      "        23, 22, 12,  5,  3, 11, 23, 26, 31, 13, 13, 12, 10, 25, 11,  4,  5, 17,\n",
      "         4, 32, 15,  6, 20, 12, 11,  4, 12,  5, 14, 21,  4,  8, 18,  9, 11,  5,\n",
      "        15, 19,  6, 31,  6,  8,  4, 19,  6, 32,  8, 15, 23, 28,  3,  6,  6]))}\n",
      "{'sequential': True, 'use_vocab': True, 'init_token': '<init>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'fix_length': 32, 'dtype': torch.int64, 'preprocessing': None, 'postprocessing': None, 'lower': True, 'tokenizer_args': (<bound method ChatbotDataLoader._tokenizer of <data_loader.data_loaders.ChatbotDataLoader object at 0x13058f370>>, 'en'), 'tokenize': <bound method ChatbotDataLoader._tokenizer of <data_loader.data_loaders.ChatbotDataLoader object at 0x13058f370>>, 'include_lengths': True, 'batch_first': False, 'pad_token': '<pad>', 'pad_first': False, 'truncate_first': False, 'stop_words': None, 'is_target': False, 'vocab': <torchtext.vocab.Vocab object at 0x1325475e0>}\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(data_loader.train_iter):\n",
    "    print(vars(batch))\n",
    "#     print(vars(batch.dataset))\n",
    "    print(vars(batch.dataset.fields['talk']))\n",
    "#     print(len(batch.dataset.examples))\n",
    "#     for ex in batch.dataset.examples:\n",
    "#         print(vars(ex))\n",
    "    if idx == 1:\n",
    "        break\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-876510bb4606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'splits' is not defined"
     ]
    }
   ],
   "source": [
    "len(splits[0].examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits[1].examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221282"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.TEXT.vocab.stoi['<PAS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iter = BucketIterator(splits[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = BucketIterator(splits[1], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Field' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d3ce5d0ac8ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Field' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "for i in valid_iter:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, vocab_size, padding_idx, hidden_size, embed_size, n_layers=1, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(input_size=embed_size, hidden_size=hidden_size, num_layers=1,\n",
    "                          bidirectional=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        emb = self.embedding(input_seq)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatbotModel(100, 0, 256, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('embedding', Embedding(100, 50, padding_idx=0)),\n",
       "              ('gru', GRU(50, 256, bidirectional=True))]),\n",
       " 'vocab_size': 100,\n",
       " 'padding_idx': 0,\n",
       " 'n_layers': 1,\n",
       " 'hidden_size': 256,\n",
       " 'embed_size': 50,\n",
       " 'dropout': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(np.random.rand(32, 50, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.squeeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-de36ccadd6c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlast_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    735\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
     ]
    }
   ],
   "source": [
    "last_hidden = None\n",
    "output, hidden = gru(torch.tensor(np.random.rand(32, 50, 256)), torch.tensor(np.random.rand(1, 50, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.tensor(np.random.randint(5, size=(5, 3)))\n",
    "lens = torch.tensor([3, 2,5,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 3],\n",
       "        [3, 1, 1],\n",
       "        [3, 4, 3],\n",
       "        [1, 4, 0],\n",
       "        [0, 2, 2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 5, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "packed = nn.utils.rnn.pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([3, 0, 3, 1, 0, 4, 0, 1, 3, 3]), batch_sizes=tensor([5, 3, 2, 1, 1]), sorted_indices=tensor([2, 0, 1, 3, 4]), unsorted_indices=tensor([1, 2, 0, 3, 4]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 3, 1, 0, 4, 0, 1, 3, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not PackedSequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f77b1529761d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not PackedSequence"
     ]
    }
   ],
   "source": [
    "emb(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLL Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'encoder_arch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1d71f3508df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m encoder = config.init_obj(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m'encoder_arch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Program/Git/chatbot/parse_config.py\u001b[0m in \u001b[0;36minit_obj\u001b[0;34m(self, name, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmodule_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_args\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Overwriting kwargs given in config file is not allowed'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Program/Git/chatbot/parse_config.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Access items like ordinary dict.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'encoder_arch'"
     ]
    }
   ],
   "source": [
    "encoder = config.init_obj(\n",
    "        'encoder_arch', module_arch,\n",
    "        vocab_size=data_loader.vocab_size,\n",
    "        padding_idx=data_loader.padding_idx,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        embed_size=config['embed_size']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/rnn.py:57: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "encoder = config.init_obj(\n",
    "        'encoder_arch', module_arch,\n",
    "        vocab_size=data_loader.vocab_size,\n",
    "        padding_idx=data_loader.padding_idx,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        embed_size=config['embed_size']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('embedding', Embedding(21928, 50, padding_idx=1)),\n",
       "              ('gru', GRU(50, 256, dropout=0.1, bidirectional=True))]),\n",
       " 'vocab_size': 21928,\n",
       " 'padding_idx': 1,\n",
       " 'n_layers': 1,\n",
       " 'hidden_size': 256,\n",
       " 'embed_size': 50,\n",
       " 'dropout': 0.1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatbotEncoder\n"
     ]
    }
   ],
   "source": [
    "print(type(encoder).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "rnn = nn.GRU(input_size=50, hidden_size=64, num_layers=2, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(20, 32, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn(2 * 2, 32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = rnn(a, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1238, -0.0801, -0.0751,  ..., -0.1777,  0.0315,  0.2147],\n",
       "         [ 0.2452, -0.5233, -0.1172,  ...,  0.0260, -0.2557,  0.0231],\n",
       "         [-0.3241, -0.2272, -0.1784,  ..., -0.1512, -0.1940,  0.5007],\n",
       "         ...,\n",
       "         [ 0.2113,  0.1761, -0.4286,  ..., -0.1313, -0.4878,  0.1818],\n",
       "         [ 0.1389,  0.0497,  0.0418,  ..., -0.0419,  0.0566,  0.3900],\n",
       "         [ 0.4436,  0.0784, -0.3300,  ..., -0.0707, -0.1370, -0.1538]]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a8d540538145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "hidden[-1] == output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1238, -0.0801, -0.0751,  ..., -0.1777,  0.0315,  0.2147],\n",
       "        [ 0.2452, -0.5233, -0.1172,  ...,  0.0260, -0.2557,  0.0231],\n",
       "        [-0.3241, -0.2272, -0.1784,  ..., -0.1512, -0.1940,  0.5007],\n",
       "        ...,\n",
       "        [ 0.2113,  0.1761, -0.4286,  ..., -0.1313, -0.4878,  0.1818],\n",
       "        [ 0.1389,  0.0497,  0.0418,  ..., -0.0419,  0.0566,  0.3900],\n",
       "        [ 0.4436,  0.0784, -0.3300,  ..., -0.0707, -0.1370, -0.1538]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatbotEncoder(\n",
      "  (embedding): Embedding(100, 50, padding_idx=1)\n",
      "  (gru): GRU(50, 256, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "Trainable parameters: 478088\n",
      "LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(100, 50, padding_idx=1)\n",
      "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gru): GRU(256, 256, dropout=0.1)\n",
      "  (concat): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (attn): Attention(\n",
      "    (attn): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 688364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hlu/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/rnn.py:57: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "encoder = config.init_obj(\n",
    "    'encoder_arch', module_arch,\n",
    "    vocab_size=data_loader.vocab_size,\n",
    "    padding_idx=data_loader.padding_idx,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    embed_size=config['embed_size']\n",
    ")\n",
    "logger.info(encoder)\n",
    "decoder = config.init_obj(\n",
    "    'decoder_arch', module_arch,\n",
    "    embedding=encoder.embedding,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    vocab_size=data_loader.vocab_size\n",
    ")\n",
    "logger.info(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.0961e-01, -3.1895e-01, -6.4349e-02,  ...,  1.8628e-01,\n",
       "           4.3406e-01, -1.7006e-03],\n",
       "         [-8.6427e-01, -4.6732e-01, -1.0612e-01,  ..., -3.1088e-01,\n",
       "          -1.8132e-01,  2.2435e-01],\n",
       "         [-4.6097e-01,  4.7562e-01, -1.4677e-01,  ..., -2.4477e-02,\n",
       "           1.8857e-01,  3.1170e-01],\n",
       "         ...,\n",
       "         [ 9.7691e-01, -6.8664e-01,  3.9081e-01,  ...,  7.2344e-02,\n",
       "          -2.9403e-01, -1.6083e-01],\n",
       "         [ 1.4220e-01, -7.6799e-01,  1.2404e-01,  ...,  3.6330e-01,\n",
       "          -3.6989e-01,  4.0256e-01],\n",
       "         [-1.1044e+00, -2.8971e-01,  1.0354e+00,  ...,  6.3056e-02,\n",
       "          -3.6093e-01,  4.2395e-02]],\n",
       "\n",
       "        [[-4.2769e-02, -1.7248e-01,  6.9871e-02,  ..., -1.1662e-01,\n",
       "           3.2323e-01,  1.0613e-01],\n",
       "         [-6.9177e-01, -2.7251e-01, -6.4256e-03,  ..., -1.9466e-01,\n",
       "          -1.2310e-01,  2.2617e-01],\n",
       "         [-9.1384e-02,  3.9609e-01, -2.1645e-01,  ..., -6.9060e-02,\n",
       "           1.6677e-01,  1.4670e-01],\n",
       "         ...,\n",
       "         [ 6.9007e-01, -3.8785e-01,  4.8208e-01,  ...,  8.1137e-02,\n",
       "          -1.8475e-01, -6.6035e-02],\n",
       "         [ 6.6680e-02, -6.2003e-01,  1.7486e-01,  ...,  2.6541e-01,\n",
       "          -3.5272e-01,  1.9419e-01],\n",
       "         [-6.8568e-01, -2.2116e-01,  6.7455e-01,  ..., -1.1769e-02,\n",
       "          -4.1227e-01,  1.3998e-01]],\n",
       "\n",
       "        [[ 7.4679e-02, -3.3076e-02,  1.9369e-01,  ..., -2.6453e-01,\n",
       "           1.1004e-01,  1.0106e-01],\n",
       "         [-3.7997e-01,  2.5118e-02, -5.2600e-02,  ..., -1.4147e-01,\n",
       "          -1.2503e-01,  1.1335e-01],\n",
       "         [-1.4929e-01,  2.6230e-01, -2.0644e-01,  ..., -6.2814e-02,\n",
       "           6.1814e-02,  2.5589e-01],\n",
       "         ...,\n",
       "         [ 3.7010e-01, -1.4409e-01,  4.6026e-01,  ...,  6.7747e-02,\n",
       "          -9.1747e-02, -2.9368e-02],\n",
       "         [-1.2960e-03, -4.9518e-01,  3.1706e-01,  ...,  2.5268e-01,\n",
       "          -3.8895e-01,  8.0497e-02],\n",
       "         [-4.3349e-01, -1.7412e-01,  4.3534e-01,  ...,  6.7167e-02,\n",
       "          -3.9927e-01,  6.3809e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 6.4364e-02,  1.1767e-01, -4.9304e-02,  ...,  1.7733e-01,\n",
       "          -4.8025e-02,  1.9636e-01],\n",
       "         [ 7.5162e-02,  1.2922e-01,  1.0272e-01,  ..., -3.3919e-01,\n",
       "          -6.1304e-01,  4.7053e-04],\n",
       "         [-6.1885e-02,  3.5212e-02,  3.5058e-01,  ...,  5.4909e-02,\n",
       "          -1.5244e-01, -1.7755e-01],\n",
       "         ...,\n",
       "         [-8.3445e-02,  3.4130e-01,  1.2858e-01,  ..., -8.6672e-03,\n",
       "          -4.2911e-01,  5.0954e-01],\n",
       "         [-1.0046e-01,  2.3358e-01, -3.2331e-02,  ...,  1.4585e-01,\n",
       "          -2.7103e-01, -7.8929e-02],\n",
       "         [-7.4982e-02,  7.2053e-04,  7.8384e-02,  ..., -1.1481e-01,\n",
       "          -1.1549e-01, -2.7597e-02]],\n",
       "\n",
       "        [[-2.0229e-01,  5.0405e-02, -5.4283e-02,  ...,  7.6961e-02,\n",
       "          -2.7573e-01,  3.0474e-01],\n",
       "         [ 1.5354e-01,  2.0215e-01,  2.9067e-01,  ..., -5.6592e-01,\n",
       "          -7.6262e-01,  7.6915e-02],\n",
       "         [-4.2931e-02, -7.5109e-02,  5.4320e-01,  ...,  6.0202e-02,\n",
       "          -1.1570e-01,  2.0120e-02],\n",
       "         ...,\n",
       "         [ 5.4116e-02,  4.4219e-01,  8.9115e-02,  ...,  4.9122e-02,\n",
       "          -4.7667e-01,  5.4942e-01],\n",
       "         [ 1.6828e-02,  1.8742e-01,  7.2984e-02,  ...,  4.2737e-01,\n",
       "          -3.5106e-01, -1.3974e-01],\n",
       "         [-2.2478e-01, -2.8369e-01, -5.4236e-02,  ..., -1.7845e-01,\n",
       "          -2.7242e-01,  5.3358e-02]],\n",
       "\n",
       "        [[-4.3364e-01, -7.1435e-02,  1.8686e-01,  ..., -2.1552e-01,\n",
       "          -4.9161e-01,  4.7610e-01],\n",
       "         [ 1.2399e-01,  1.0449e-01,  3.7180e-01,  ..., -7.7590e-01,\n",
       "          -1.2965e+00,  7.8527e-02],\n",
       "         [-1.3890e-01, -1.7195e-01,  5.7953e-01,  ...,  1.5351e-01,\n",
       "          -1.1393e-01,  5.5085e-01],\n",
       "         ...,\n",
       "         [ 3.2839e-01,  4.3616e-01,  1.5071e-01,  ...,  1.8452e-02,\n",
       "          -4.8494e-01,  4.0618e-01],\n",
       "         [ 9.9613e-02,  1.9163e-01,  5.5850e-03,  ...,  8.5145e-01,\n",
       "          -2.7097e-01, -3.2535e-02],\n",
       "         [-3.0963e-01, -6.2512e-01, -1.9433e-01,  ..., -3.0901e-01,\n",
       "          -3.3732e-01, -1.4248e-03]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.8814e-01, -3.0856e-01, -6.4260e-02,  ...,  1.8416e-01,\n",
       "           4.0871e-01, -1.7006e-03],\n",
       "         [-6.9845e-01, -4.3603e-01, -1.0573e-01,  ..., -3.0124e-01,\n",
       "          -1.7935e-01,  2.2066e-01],\n",
       "         [-4.3087e-01,  4.4273e-01, -1.4572e-01,  ..., -2.4472e-02,\n",
       "           1.8637e-01,  3.0199e-01],\n",
       "         ...,\n",
       "         [ 7.5173e-01, -5.9582e-01,  3.7206e-01,  ...,  7.2218e-02,\n",
       "          -2.8584e-01, -1.5946e-01],\n",
       "         [ 1.4124e-01, -6.4576e-01,  1.2341e-01,  ...,  3.4811e-01,\n",
       "          -3.5390e-01,  3.8214e-01],\n",
       "         [-8.0207e-01, -2.8187e-01,  7.7608e-01,  ...,  6.2973e-02,\n",
       "          -3.4604e-01,  4.2370e-02]],\n",
       "\n",
       "        [[-4.2743e-02, -1.7079e-01,  6.9757e-02,  ..., -1.1610e-01,\n",
       "           3.1242e-01,  1.0573e-01],\n",
       "         [-5.9912e-01, -2.6596e-01, -6.4255e-03,  ..., -1.9224e-01,\n",
       "          -1.2248e-01,  2.2239e-01],\n",
       "         [-9.1130e-02,  3.7660e-01, -2.1313e-01,  ..., -6.8950e-02,\n",
       "           1.6524e-01,  1.4566e-01],\n",
       "         ...,\n",
       "         [ 5.9803e-01, -3.6951e-01,  4.4791e-01,  ...,  8.0959e-02,\n",
       "          -1.8268e-01, -6.5940e-02],\n",
       "         [ 6.6581e-02, -5.5115e-01,  1.7310e-01,  ...,  2.5934e-01,\n",
       "          -3.3879e-01,  1.9179e-01],\n",
       "         [-5.9520e-01, -2.1762e-01,  5.8797e-01,  ..., -1.1768e-02,\n",
       "          -3.9040e-01,  1.3907e-01]],\n",
       "\n",
       "        [[ 7.4541e-02, -3.3064e-02,  1.9131e-01,  ..., -2.5853e-01,\n",
       "           1.0959e-01,  1.0072e-01],\n",
       "         [-3.6268e-01,  2.5113e-02, -5.2551e-02,  ..., -1.4054e-01,\n",
       "          -1.2438e-01,  1.1287e-01],\n",
       "         [-1.4819e-01,  2.5644e-01, -2.0356e-01,  ..., -6.2732e-02,\n",
       "           6.1736e-02,  2.5045e-01],\n",
       "         ...,\n",
       "         [ 3.5408e-01, -1.4310e-01,  4.3030e-01,  ...,  6.7644e-02,\n",
       "          -9.1490e-02, -2.9359e-02],\n",
       "         [-1.2960e-03, -4.5831e-01,  3.0685e-01,  ...,  2.4744e-01,\n",
       "          -3.7045e-01,  8.0323e-02],\n",
       "         [-4.0824e-01, -1.7238e-01,  4.0977e-01,  ...,  6.7066e-02,\n",
       "          -3.7933e-01,  6.3723e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 6.4275e-02,  1.1713e-01, -4.9264e-02,  ...,  1.7549e-01,\n",
       "          -4.7988e-02,  1.9388e-01],\n",
       "         [ 7.5021e-02,  1.2851e-01,  1.0236e-01,  ..., -3.2676e-01,\n",
       "          -5.4626e-01,  4.7053e-04],\n",
       "         [-6.1806e-02,  3.5197e-02,  3.3689e-01,  ...,  5.4854e-02,\n",
       "          -1.5127e-01, -1.7571e-01],\n",
       "         ...,\n",
       "         [-8.3252e-02,  3.2863e-01,  1.2787e-01,  ..., -8.6670e-03,\n",
       "          -4.0458e-01,  4.6959e-01],\n",
       "         [-1.0012e-01,  2.2943e-01, -3.2320e-02,  ...,  1.4483e-01,\n",
       "          -2.6458e-01, -7.8766e-02],\n",
       "         [-7.4842e-02,  7.2053e-04,  7.8224e-02,  ..., -1.1431e-01,\n",
       "          -1.1498e-01, -2.7590e-02]],\n",
       "\n",
       "        [[-1.9957e-01,  5.0362e-02, -5.4229e-02,  ...,  7.6810e-02,\n",
       "          -2.6895e-01,  2.9565e-01],\n",
       "         [ 1.5235e-01,  1.9945e-01,  2.8275e-01,  ..., -5.1236e-01,\n",
       "          -6.4262e-01,  7.6764e-02],\n",
       "         [-4.2905e-02, -7.4968e-02,  4.9541e-01,  ...,  6.0129e-02,\n",
       "          -1.1519e-01,  2.0118e-02],\n",
       "         ...,\n",
       "         [ 5.4063e-02,  4.1546e-01,  8.8880e-02,  ...,  4.9083e-02,\n",
       "          -4.4357e-01,  5.0008e-01],\n",
       "         [ 1.6826e-02,  1.8525e-01,  7.2855e-02,  ...,  4.0312e-01,\n",
       "          -3.3731e-01, -1.3884e-01],\n",
       "         [-2.2107e-01, -2.7631e-01, -5.4183e-02,  ..., -1.7658e-01,\n",
       "          -2.6587e-01,  5.3307e-02]],\n",
       "\n",
       "        [[-4.0836e-01, -7.1314e-02,  1.8472e-01,  ..., -2.1224e-01,\n",
       "          -4.5549e-01,  4.4312e-01],\n",
       "         [ 1.2336e-01,  1.0411e-01,  3.5556e-01,  ..., -6.5035e-01,\n",
       "          -8.6082e-01,  7.8366e-02],\n",
       "         [-1.3802e-01, -1.7028e-01,  5.2232e-01,  ...,  1.5231e-01,\n",
       "          -1.1344e-01,  5.0116e-01],\n",
       "         ...,\n",
       "         [ 3.1708e-01,  4.1045e-01,  1.4958e-01,  ...,  1.8450e-02,\n",
       "          -4.5019e-01,  3.8523e-01],\n",
       "         [ 9.9285e-02,  1.8932e-01,  5.5849e-03,  ...,  6.9183e-01,\n",
       "          -2.6453e-01, -3.2524e-02],\n",
       "         [-3.0010e-01, -5.5468e-01, -1.9192e-01,  ..., -2.9954e-01,\n",
       "          -3.2508e-01, -1.4248e-03]]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_reshape = hidden.view(2, 2, -1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 32, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 64])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_reshape[-1:, :1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[[1,2],[3,4]],[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(4,5,6)[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones(1, 1, dtype=torch.long) * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
